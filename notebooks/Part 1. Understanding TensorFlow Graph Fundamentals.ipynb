{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline \n",
    "\n",
    " - Dataflow Programming\n",
    "     - Intro to Dataflow Programming\n",
    "     - Operations and Tensors\n",
    "\n",
    "\n",
    " - The Graph is defined as a protobuf\n",
    " \t- Exploring the graph protobuf\n",
    " \t- Exporting and editing the graph protobuf\n",
    "\n",
    "\n",
    " - How to execute a graph program\n",
    " \t- Executing our first session\n",
    " \t- Special Operation Placeholders\n",
    "\n",
    "\n",
    " - Graph building conventions\n",
    " \t- Opinionated convention\n",
    " \t- All about naming\n",
    " \t- operation and tensor naming convention\n",
    " \t- get_tensor and get_operation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataflow Programming\n",
    "\n",
    "###  Intro to Dataflow Programming\n",
    "Before jumping into TensorFlow, we should understand the general paradigm of [Dataflow or Datastream programming](https://en.wikipedia.org/wiki/Dataflow_programming). At the end of this section, you should be able to use TensorFlow as an overly complicated scientific calculator. \n",
    "\n",
    "The main idea behind Dataflow is to define computation graphs. Each node in the graph represents a function such as addition, matrix multiplication, etc. Each edge represents the inputs/outputs of these functions. Once the computation graph is defined, we can evaluate nodes of interest.\n",
    "\n",
    "<img src=\"../figures/graph.png\" width=\"400\"/>\n",
    "\n",
    "In the example above, we would like to evaluate $G$. You may notice a couple things:\n",
    "\n",
    "1. Only a subgraph, which excludes node $F$, is required to evaluate node $G$ outputs. \n",
    "\n",
    "2. Collections of contiguous nodes can conceptually behave as a single node. For example, the collection of $\\{C, D, E\\}$ takes one input from $\\{B\\}$ and produces two outputs leading towards $\\{F\\}$ and $\\{G\\}$.\n",
    "\n",
    "\n",
    "We describe some very desirable properties: \n",
    "1. Only executing necessary subgraphs means lower computation overhead.\n",
    "\n",
    "2. Being able to form contiguous node subgraphs allow for distributed function placement across multiple devices. \n",
    "\n",
    "These are just [some](https://www.tensorflow.org/programmers_guide/graphs#why_dataflow_graphs) of the design reasons TensorFlow follows the Dataflow programming model.\n",
    "\n",
    "So enough theory, how does TensorFlow implement the Dataflow model? TensorFlow implements the Dataflow execution model in C++ known as the \"TensorFlow runtime\". Interfacing with the TensorFlow runtime are low level APIs currently available in [Python](https://www.tensorflow.org/api_docs/python), [GoLang](https://godoc.org/github.com/tensorflow/tensorflow/tensorflow/go), [Java](https://www.tensorflow.org/api_docs/java/reference/org/tensorflow/package-summary), and [C++](https://www.tensorflow.org/api_docs/cc). These low level APIs build *Graphs*, and execute the TensorFlow runtime in the form of *Sessions*. Computation graphs are ultimately executed on device hardware (CPU, GPU, [TPU](https://en.wikipedia.org/wiki/Tensor_processing_unit)). We will be focusing on the Python API to create Graphs, and run Sessions.\n",
    "\n",
    "<img src=\"../figures/API_layers.png\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations and Tensors\n",
    "\n",
    "In TensorFlowâ€™s computation graph, nodes are [Operations](https://www.tensorflow.org/versions/master/api_docs/python/tf/Operation), and edges are [Tensors](https://www.tensorflow.org/versions/master/api_docs/python/tf/Tensor). Operations then simply have input and output Tensors. Let's recreate our previous example graph with arbitrary ops in tensorflow. These basic arbitrary ops can be found [here](https://www.tensorflow.org/api_docs/python/tf#functions). The graph can be visualized here via iframe ([thanks jakub arnold!](https://blog.jakuba.net/2017/05/30/tensorflow-visualization.html)), or visualized on your local tensorboard at `localhost:6006`\n",
    "\n",
    "We create a graph `g1` and add operations $\\{A,B,C,D,E,F,G\\}$. Note that `tf.constant` is considered an operation, it takes in no tensors as input and produces a single tensor as output. It is a subtle, but important distiction to make that all nodes in the TensorFlow graph are  [Operations](https://www.tensorflow.org/versions/master/api_docs/python/tf/Operation).\n",
    "\n",
    "In the python API, `tf.Operation` will return a `tf.Tensor` which can be wired as inputs into another `tf.Operation`. `tf.Tensor` was built analogously to [numpy arrays](https://docs.scipy.org/doc/numpy/reference/generated/numpy.array.html). Tensors have a [datatype](https://www.tensorflow.org/api_docs/python/tf/DType) such as `float32`, `int32`, or `string`. They can have a shape such as a scalar, vector, matrix, cube, with a corresponding dimension 0, 1, 2, 3. In this first example, we will just deal with `float32` scalar tensors to keep it simple.\n",
    "\n",
    "\n",
    "If you run the code above you should successfully build a TensorFlow graph. Congrats!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script src=&quot;//cdnjs.cloudflare.com/ajax/libs/polymer/0.3.3/platform.js&quot;></script>\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.694613287991&quot;).pbtxt = 'node {\\n  name: &quot;A&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.800000011921\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;B&quot;\\n  op: &quot;Abs&quot;\\n  input: &quot;A&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;C&quot;\\n  op: &quot;Cos&quot;\\n  input: &quot;B&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;D&quot;\\n  op: &quot;Ceil&quot;\\n  input: &quot;B&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;E&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;C&quot;\\n  input: &quot;D&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;F&quot;\\n  op: &quot;Acos&quot;\\n  input: &quot;C&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;G&quot;\\n  op: &quot;Asin&quot;\\n  input: &quot;E&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.694613287991&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from src import cloud_visualizer\n",
    "\n",
    "g1 = tf.Graph() \n",
    "\n",
    "with g1.as_default(): \n",
    "    a = tf.constant(-0.8, name=\"A\") # or a = -0.8\n",
    "    b = tf.abs(a, name=\"B\")\n",
    "    \n",
    "    c = tf.cos(b, name=\"C\")\n",
    "    d = tf.ceil(b, name=\"D\")\n",
    "    \n",
    "    e = tf.multiply(c, d, name=\"E\")\n",
    "    f = tf.acos(c, name=\"F\")\n",
    "    \n",
    "    g = tf.asin(e, name=\"G\")\n",
    "    \n",
    "tf.summary.FileWriter(\"logs\", g1).close() # write graph out to tensorboard for visualization\n",
    "cloud_visualizer.show_graph(g1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Graph is defined as a protobuf\n",
    "\n",
    "### Exploring the graph protobuf\n",
    "\n",
    "It is easy to get overwhelmed with all functions and operations related to `tf.Graph`. In the end, just remember that all we have done so far is defining some Dataflow structure. To ingrain this into our mind, I find it helpful to understand how `tf.Graph` is serialized or represented under the hood.\n",
    "\n",
    "`tf.Graph` can be represented as a [protocol buffer](https://developers.google.com/protocol-buffers/docs/overview) known as [`tf.GraphDef`](https://www.tensorflow.org/api_docs/python/tf/GraphDef).\n",
    "\n",
    "If you have worked with data formats such as `json` or `xml`, `protobufs` are just another structure format created by Google. TensorFlow uses a number of `protobuf` definitions: [`GraphDef`](https://github.com/tensorflow/tensorflow/blob/r1.3/tensorflow/core/framework/graph.proto), [`NodeDef`](https://github.com/tensorflow/tensorflow/blob/r1.3/tensorflow/core/framework/node_def.proto), and [`AttrValue`](https://github.com/tensorflow/tensorflow/blob/r1.3/tensorflow/core/framework/attr_value.proto) to name a few. \n",
    "\n",
    "We can output the `GraphDef` of `g1` quickly by using the `tf.Graph.as_graph_def()` function to look at a its text form as a `.pbtxt` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "node {\n",
       "  name: \"A\"\n",
       "  op: \"Const\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_FLOAT\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "      tensor {\n",
       "        dtype: DT_FLOAT\n",
       "        tensor_shape {\n",
       "        }\n",
       "        float_val: -0.800000011921\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"B\"\n",
       "  op: \"Abs\"\n",
       "  input: \"A\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_FLOAT\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"C\"\n",
       "  op: \"Cos\"\n",
       "  input: \"B\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_FLOAT\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"D\"\n",
       "  op: \"Ceil\"\n",
       "  input: \"B\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_FLOAT\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"E\"\n",
       "  op: \"Mul\"\n",
       "  input: \"C\"\n",
       "  input: \"D\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_FLOAT\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"F\"\n",
       "  op: \"Acos\"\n",
       "  input: \"C\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_FLOAT\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"G\"\n",
       "  op: \"Asin\"\n",
       "  input: \"E\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_FLOAT\n",
       "    }\n",
       "  }\n",
       "}\n",
       "versions {\n",
       "  producer: 24\n",
       "}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.protobuf import text_format\n",
    "\n",
    "# Let's export the graphdef protobuf as a readable text file.\n",
    "with open(\"./storage/g1.pbtxt\", \"w\") as f:\n",
    "    f.write(text_format.MessageToString(g1.as_graph_def()))\n",
    "\n",
    "g1.as_graph_def() # display the graph inline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the `.pbtxt` files we can see that the `GraphDef` contains many `NodeDef` objects. Each of these has a `name`, `op`, `input`, and `attr`. \n",
    "\n",
    " - `name` refers to the the name of operation, and we can grab specific ops using the [`tf.Graph.get_operation_by_name`](https://www.tensorflow.org/api_docs/python/tf/Graph#get_operation_by_name) method. \n",
    "\n",
    " - `op` refers to the TensorFlow `Operation` the node references. \n",
    "\n",
    " - `input` refers to the outputs coming from other defined nodes, node outputs are then implicit.\n",
    "\n",
    " - `attr` is a map of attributes that vary depending on the specific to the `op` the node represents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting and editing the graph protobuf\n",
    "\n",
    "The definition laid out in `GraphDef` begs the question, can we build graphs without using the TensorFlow python API? The answer is yes. \n",
    "\n",
    "Let's output a graph as a protobuf text, edit it and import it back into python. In the future we obviously would want to use the python API for building graphs. We will be creating operation $Z$, which adds the outputs from operation $G$ and $F$.\n",
    "\n",
    "However, I hope that going through the protobuf text files show that `tf.Graph` is simply an API to declare graph structure, and that we can even bypass the API completely by writing it as a `.pbtxt` file. To re-emphasize, **all we have done is declare a graph structure**, we have not executed anything. Operation $Z$ has been added to `g2.pbtxt` for your convenience. As you can see after running the code $Z$ on the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script src=&quot;//cdnjs.cloudflare.com/ajax/libs/polymer/0.3.3/platform.js&quot;></script>\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.491283680841&quot;).pbtxt = 'node {\\n  name: &quot;A&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.800000011921\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;B&quot;\\n  op: &quot;Abs&quot;\\n  input: &quot;A&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;C&quot;\\n  op: &quot;Floor&quot;\\n  input: &quot;B&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;D&quot;\\n  op: &quot;Ceil&quot;\\n  input: &quot;B&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;E&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;C&quot;\\n  input: &quot;D&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;F&quot;\\n  op: &quot;Acos&quot;\\n  input: &quot;C&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;G&quot;\\n  op: &quot;Asin&quot;\\n  input: &quot;E&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Z&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;F&quot;\\n  input: &quot;G&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.491283680841&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from google.protobuf import text_format\n",
    "\n",
    "# Let's import our new graphdef protobuf\n",
    "with open(\"./storage/g2.pbtxt\", \"r\") as f: \n",
    "    graphdef = text_format.Parse(f.read(), tf.GraphDef())\n",
    "\n",
    "g2 = tf.Graph() \n",
    "with g2.as_default():\n",
    "    tf.import_graph_def(graph_def=graphdef, name=\"\") # import the graph def into our new graph.\n",
    "\n",
    "cloud_visualizer.show_graph(g2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute a Graph through a Session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executing our first session\n",
    "\n",
    "Now that we have the basics of constructing graphs, we want to execute to get the actual output. We do this in the form of `tf.Session` which creates an environment, grabs computation power, and places graph operations on their proper devices. Don't be suprised if your computer fans start turning. In our simple case, it defaults to the CPU.\n",
    "\n",
    "We will pass in the graph we just built, `g2` to compute the tensor outputs of $Z$. By default, the name of this tensor is `Z:0`. We will go into these naming conventions later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5708\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session(graph=g2);\n",
    "print(sess.run(g2.get_tensor_by_name(\"Z:0\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Special Operation Placeholders\n",
    "\n",
    "With our current graph, we can only evaluate our nodes based on the constant we've defined. It would be nice to input data at the session runtime. This is what the special operation `tf.Placeholder` allows us to do.\n",
    "\n",
    "We specify a datatype, and shape for the `tf.Placeholder` operation and we can pass in inputs using the `feed_dict` kwarg for a session. Let's rebuild the graph and try this. If you run the code you can see we are able to feed in several values of `a` to evaluate `Z:0`, clearly a useful feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script src=&quot;//cdnjs.cloudflare.com/ajax/libs/polymer/0.3.3/platform.js&quot;></script>\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.874623862106&quot;).pbtxt = 'node {\\n  name: &quot;A&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;B&quot;\\n  op: &quot;Abs&quot;\\n  input: &quot;A&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;C&quot;\\n  op: &quot;Cos&quot;\\n  input: &quot;B&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;D&quot;\\n  op: &quot;Ceil&quot;\\n  input: &quot;B&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;E&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;C&quot;\\n  input: &quot;D&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;F&quot;\\n  op: &quot;Acos&quot;\\n  input: &quot;C&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;G&quot;\\n  op: &quot;Asin&quot;\\n  input: &quot;E&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Z&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;F&quot;\\n  input: &quot;G&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.874623862106&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from src import cloud_visualizer\n",
    "\n",
    "g3 = tf.Graph() \n",
    "\n",
    "with g3.as_default(): \n",
    "    a = tf.placeholder(dtype=tf.float32, shape=None, name=\"A\") # or a = -0.8\n",
    "    b = tf.abs(a, name=\"B\")\n",
    "    \n",
    "    c = tf.cos(b, name=\"C\")\n",
    "    d = tf.ceil(b, name=\"D\")\n",
    "    \n",
    "    e = tf.multiply(c, d, name=\"E\")\n",
    "    f = tf.acos(c, name=\"F\")\n",
    "    \n",
    "    g = tf.asin(e, name=\"G\")\n",
    "    \n",
    "    z = tf.add(f, g, name=\"Z\")\n",
    "    \n",
    "tf.summary.FileWriter(\"logs\", g3).close() # write graph out to tensorboard for visualization\n",
    "cloud_visualizer.show_graph(g3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.57079625,  1.0167675 ,         nan],\n",
       "       [ 1.0167675 ,  1.57079625,  0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.Session(graph=g3)\n",
    "sess.run(\"Z:0\", feed_dict={a: [[1, 2, -3], [2, 1, 0]]}) # Can take in arbitrary shapes of data to eval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph naming conventions\n",
    "\n",
    "### Opinionated convention\n",
    "\n",
    "TensorFlow is not an opionionated API. It is very forgiving and there are many ways to build the same functional graph. For example, we can build `g1` like the following. Why do `a` and `e` still work if TensorFlow only works with Operations? Also what is the default name of an operation if I don't pass the name?\n",
    "\n",
    " - For `a`, TensorFlow will automatically convert \"[tensor-like-objects](https://www.tensorflow.org/programmers_guide/graphs#tensor-like_objects)\" into tf.constant operations returning the converted tensor. This makes `a` an Operation. \n",
    " \n",
    " - For `e`, TensorFlow will map [appropiate tensorflow functions via python operator overloading methods](https://stackoverflow.com/questions/37900780/in-tensorflow-what-is-the-difference-between-tf-add-and-operator), turning `+`, `/`, `-`, and `*`, into, you guessed it, Operations.\n",
    "\n",
    "With all the ways to create the same graph, we suggest a couple conventions to keep graphs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script src=&quot;//cdnjs.cloudflare.com/ajax/libs/polymer/0.3.3/platform.js&quot;></script>\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.879606088539&quot;).pbtxt = 'node {\\n  name: &quot;Abs/x&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.800000011921\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Abs&quot;\\n  op: &quot;Abs&quot;\\n  input: &quot;Abs/x&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Cos&quot;\\n  op: &quot;Cos&quot;\\n  input: &quot;Abs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Ceil&quot;\\n  op: &quot;Ceil&quot;\\n  input: &quot;Abs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;Cos&quot;\\n  input: &quot;Ceil&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Acos&quot;\\n  op: &quot;Acos&quot;\\n  input: &quot;Cos&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Asin&quot;\\n  op: &quot;Asin&quot;\\n  input: &quot;mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.879606088539&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from src import cloud_visualizer\n",
    "\n",
    "g1 = tf.Graph() \n",
    "\n",
    "with g1.as_default(): \n",
    "    a = -0.8\n",
    "    b = tf.abs(a)\n",
    "    \n",
    "    c = tf.cos(b)\n",
    "    d = tf.ceil(b)\n",
    "    \n",
    "    e = c*d\n",
    "    f = tf.acos(c)\n",
    "    \n",
    "    g = tf.asin(e)\n",
    "    \n",
    "tf.summary.FileWriter(\"logs\", g1).close() # write graph out to tensorboard for visualization\n",
    "cloud_visualizer.show_graph(g1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
